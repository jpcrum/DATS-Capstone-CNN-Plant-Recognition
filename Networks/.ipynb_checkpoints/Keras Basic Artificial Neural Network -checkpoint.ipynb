{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjcrum\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drug experiment on half young, half old\n",
    "#95% old people had side effects, 95% young people did not have side effects\n",
    "\n",
    "#Anomaly \n",
    "for i in range(50):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "#Expected\n",
    "for i in range(1000):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Keras wants numpy array\n",
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjcrum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1)) #normalizing\n",
    "#Scale all training data (13-100) to 0-1, reshape because function doesnt take 1d array\n",
    "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear stack of layers, each element in array is a layer\n",
    "model = Sequential([\n",
    "    Dense(16, input_shape = (1,), activation='relu'), #number of neurons in layer, only this layer needs input shape (1D)\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dense(2, activation = 'softmax') #output layer, 2 nodes for 2 classes (young/old)\n",
    "]) \n",
    "#model.add([layer]) also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compile model\n",
    "#Arguments = optimizer(learning rate), loss, metrics\n",
    "model.compile(Adam(lr = 0.0001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1680 samples, validate on 420 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.6628 - acc: 0.5429 - val_loss: 0.6456 - val_acc: 0.5786\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6414 - acc: 0.6173 - val_loss: 0.6181 - val_acc: 0.6905\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.6180 - acc: 0.6923 - val_loss: 0.5914 - val_acc: 0.7548\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.5955 - acc: 0.7226 - val_loss: 0.5644 - val_acc: 0.7905\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.5725 - acc: 0.7565 - val_loss: 0.5365 - val_acc: 0.8262\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.5492 - acc: 0.7923 - val_loss: 0.5079 - val_acc: 0.8619\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.5261 - acc: 0.8179 - val_loss: 0.4796 - val_acc: 0.8762\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.5030 - acc: 0.8262 - val_loss: 0.4524 - val_acc: 0.9000\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.4807 - acc: 0.8506 - val_loss: 0.4242 - val_acc: 0.9119\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.4591 - acc: 0.8619 - val_loss: 0.3977 - val_acc: 0.9143\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.4392 - acc: 0.8750 - val_loss: 0.3730 - val_acc: 0.9286\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.4212 - acc: 0.8833 - val_loss: 0.3500 - val_acc: 0.9429\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.4051 - acc: 0.8851 - val_loss: 0.3295 - val_acc: 0.9524\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.3909 - acc: 0.8905 - val_loss: 0.3115 - val_acc: 0.9643\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.3784 - acc: 0.8982 - val_loss: 0.2948 - val_acc: 0.9643\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.3676 - acc: 0.9018 - val_loss: 0.2799 - val_acc: 0.9643\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.3582 - acc: 0.9065 - val_loss: 0.2659 - val_acc: 0.9643\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.3500 - acc: 0.9036 - val_loss: 0.2550 - val_acc: 0.9714\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.3430 - acc: 0.9101 - val_loss: 0.2435 - val_acc: 0.9643\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.3371 - acc: 0.9089 - val_loss: 0.2341 - val_acc: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2276c5b6e48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model, data, labels, validation size(takes last n%), batch size, shuffle(default = True, each epoch is in different order), verbose is printing \n",
    "model.fit(scaled_train_samples, train_labels, validation_split = 0.2, batch_size = 10, epochs = 20, shuffle = True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjcrum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "#Anomaly \n",
    "for i in range(10):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65, 100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "\n",
    "#Expected\n",
    "for i in range(200):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65, 100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "#Keras wants numpy array\n",
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1)) #normalizing\n",
    "#Scale all training data (13-100) to 0-1, reshape because function doesnt take 1d array\n",
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73734075 0.26265925]\n",
      "[0.3629263 0.6370737]\n",
      "[0.54804707 0.45195296]\n",
      "[0.07678387 0.92321616]\n",
      "[0.87280095 0.12719905]\n",
      "[0.32507023 0.6749298 ]\n",
      "[0.90398    0.09602005]\n",
      "[0.11168712 0.88831294]\n",
      "[0.89832485 0.10167515]\n",
      "[0.32507023 0.6749298 ]\n",
      "[0.54804707 0.45195296]\n",
      "[0.0827338  0.91726613]\n",
      "[0.9084839  0.09151606]\n",
      "[0.4025615 0.5974385]\n",
      "[0.7970498  0.20295022]\n",
      "[0.19748384 0.8025162 ]\n",
      "[0.90362185 0.09637818]\n",
      "[0.0665645  0.93343544]\n",
      "[0.75327086 0.24672918]\n",
      "[0.3629263 0.6370737]\n",
      "[0.8558617  0.14413826]\n",
      "[0.21112554 0.7888744 ]\n",
      "[0.6857598 0.3142402]\n",
      "[0.16058014 0.83941984]\n",
      "[0.62914413 0.3708558 ]\n",
      "[0.18451743 0.81548256]\n",
      "[0.87280095 0.12719905]\n",
      "[0.07124831 0.9287517 ]\n",
      "[0.5892014 0.4107986]\n",
      "[0.0629392  0.93706083]\n",
      "[0.66739553 0.3326045 ]\n",
      "[0.08910024 0.91089976]\n",
      "[0.9078036 0.0921964]\n",
      "[0.2893693 0.7106307]\n",
      "[0.6857598 0.3142402]\n",
      "[0.0543643  0.94563574]\n",
      "[0.8228589 0.1771411]\n",
      "[0.0827338  0.91726613]\n",
      "[0.845998   0.15400198]\n",
      "[0.07678389 0.92321616]\n",
      "[0.76853806 0.23146193]\n",
      "[0.08910024 0.91089976]\n",
      "[0.90468556 0.09531442]\n",
      "[0.21112554 0.7888744 ]\n",
      "[0.75327086 0.24672918]\n",
      "[0.16058014 0.83941984]\n",
      "[0.9053865  0.09461349]\n",
      "[0.0543643  0.94563574]\n",
      "[0.9053865  0.09461349]\n",
      "[0.0629392  0.93706083]\n",
      "[0.9078036 0.0921964]\n",
      "[0.14958508 0.850415  ]\n",
      "[0.8102903  0.18970975]\n",
      "[0.13921808 0.8607819 ]\n",
      "[0.9067746  0.09322542]\n",
      "[0.2893693 0.7106307]\n",
      "[0.90433335 0.09566667]\n",
      "[0.27241775 0.7275823 ]\n",
      "[0.46431562 0.5356844 ]\n",
      "[0.04706734 0.95293266]\n",
      "[0.64850813 0.3514919 ]\n",
      "[0.16058014 0.83941984]\n",
      "[0.5271838  0.47281626]\n",
      "[0.30693066 0.69306934]\n",
      "[0.90289587 0.09710408]\n",
      "[0.10362651 0.89637345]\n",
      "[0.9084839  0.09151606]\n",
      "[0.0543643  0.94563574]\n",
      "[0.609356 0.390644]\n",
      "[0.34375012 0.6562499 ]\n",
      "[0.9061308  0.09386922]\n",
      "[0.38254866 0.61745137]\n",
      "[0.50622493 0.49377504]\n",
      "[0.18451743 0.81548256]\n",
      "[0.87280095 0.12719905]\n",
      "[0.13921808 0.8607819 ]\n",
      "[0.9030451 0.0969549]\n",
      "[0.27241775 0.7275823 ]\n",
      "[0.90711874 0.09288126]\n",
      "[0.08910024 0.91089976]\n",
      "[0.50622493 0.49377504]\n",
      "[0.09608483 0.9039152 ]\n",
      "[0.87280095 0.12719905]\n",
      "[0.0827338  0.91726613]\n",
      "[0.9067746  0.09322542]\n",
      "[0.30693066 0.69306934]\n",
      "[0.9064293  0.09357074]\n",
      "[0.07678387 0.92321616]\n",
      "[0.90858823 0.09141176]\n",
      "[0.22544488 0.77455515]\n",
      "[0.8927972  0.10720281]\n",
      "[0.11168712 0.88831294]\n",
      "[0.8927972  0.10720281]\n",
      "[0.32507023 0.6749298 ]\n",
      "[0.9084839  0.09151606]\n",
      "[0.38254866 0.61745137]\n",
      "[0.9061308  0.09386922]\n",
      "[0.04706734 0.95293266]\n",
      "[0.88658816 0.11341181]\n",
      "[0.07678389 0.92321616]\n",
      "[0.86475    0.13524997]\n",
      "[0.4025615 0.5974385]\n",
      "[0.86475    0.13524997]\n",
      "[0.04706734 0.95293266]\n",
      "[0.46431562 0.53568435]\n",
      "[0.0543643  0.94563574]\n",
      "[0.87280095 0.12719905]\n",
      "[0.05702526 0.94297475]\n",
      "[0.845998   0.15400198]\n",
      "[0.10362648 0.89637345]\n",
      "[0.8927972  0.10720281]\n",
      "[0.30693066 0.69306934]\n",
      "[0.46431562 0.53568435]\n",
      "[0.18451743 0.81548256]\n",
      "[0.75327086 0.24672918]\n",
      "[0.11168712 0.88831294]\n",
      "[0.90788287 0.09211718]\n",
      "[0.12946011 0.8705399 ]\n",
      "[0.8347647  0.16523536]\n",
      "[0.05182065 0.94817936]\n",
      "[0.90711874 0.09288128]\n",
      "[0.27241775 0.7275823 ]\n",
      "[0.9030451 0.0969549]\n",
      "[0.05702526 0.94297475]\n",
      "[0.8927972  0.10720281]\n",
      "[0.18451743 0.81548256]\n",
      "[0.845998   0.15400198]\n",
      "[0.05980885 0.94019115]\n",
      "[0.7035605  0.29643953]\n",
      "[0.07124831 0.9287517 ]\n",
      "[0.66739553 0.3326045 ]\n",
      "[0.10362651 0.89637345]\n",
      "[0.9067746  0.09322542]\n",
      "[0.11168712 0.88831294]\n",
      "[0.7035605 0.2964395]\n",
      "[0.07678387 0.92321616]\n",
      "[0.76853806 0.23146193]\n",
      "[0.4025615 0.5974385]\n",
      "[0.7970498  0.20295022]\n",
      "[0.05980885 0.94019115]\n",
      "[0.90289587 0.09710408]\n",
      "[0.07124831 0.9287517 ]\n",
      "[0.9084839  0.09151606]\n",
      "[0.3629263 0.6370737]\n",
      "[0.9057352  0.09426474]\n",
      "[0.12946011 0.8705399 ]\n",
      "[0.5271838  0.47281626]\n",
      "[0.32507023 0.6749298 ]\n",
      "[0.56874293 0.43125707]\n",
      "[0.0629392  0.93706083]\n",
      "[0.7970498  0.20295022]\n",
      "[0.21112554 0.7888744 ]\n",
      "[0.8927972  0.10720281]\n",
      "[0.21112554 0.7888744 ]\n",
      "[0.54804707 0.45195296]\n",
      "[0.05702526 0.94297475]\n",
      "[0.7970498  0.20295022]\n",
      "[0.32507023 0.6749298 ]\n",
      "[0.86475    0.13524997]\n",
      "[0.10362648 0.89637345]\n",
      "[0.9060828  0.09391718]\n",
      "[0.42290425 0.5770958 ]\n",
      "[0.5892014 0.4107986]\n",
      "[0.25610146 0.7438986 ]\n",
      "[0.90858823 0.09141176]\n",
      "[0.08910024 0.91089976]\n",
      "[0.5271838  0.47281626]\n",
      "[0.32507023 0.6749298 ]\n",
      "[0.9084839  0.09151606]\n",
      "[0.22544488 0.77455515]\n",
      "[0.90433335 0.09566667]\n",
      "[0.0629392  0.93706083]\n",
      "[0.9081443  0.09185565]\n",
      "[0.4025615 0.5974385]\n",
      "[0.9078036 0.0921964]\n",
      "[0.34375012 0.6562499 ]\n",
      "[0.8228589 0.1771411]\n",
      "[0.08910024 0.91089976]\n",
      "[0.9057352  0.09426474]\n",
      "[0.12946011 0.8705399 ]\n",
      "[0.9064293  0.09357074]\n",
      "[0.11168712 0.88831294]\n",
      "[0.7035605 0.2964395]\n",
      "[0.38254866 0.61745137]\n",
      "[0.845998   0.15400198]\n",
      "[0.0827338  0.91726613]\n",
      "[0.8798997  0.12010036]\n",
      "[0.42290425 0.5770958 ]\n",
      "[0.48524427 0.5147557 ]\n",
      "[0.16058014 0.83941984]\n",
      "[0.8347647  0.16523536]\n",
      "[0.16058014 0.83941984]\n",
      "[0.64850813 0.3514919 ]\n",
      "[0.38254866 0.61745137]\n",
      "[0.90858823 0.09141176]\n",
      "[0.05702526 0.94297475]\n",
      "[0.54804707 0.45195296]\n",
      "[0.04938981 0.95061016]\n",
      "[0.7035605  0.29643953]\n",
      "[0.0665645  0.93343544]\n",
      "[0.9078036 0.0921964]\n",
      "[0.10362651 0.89637345]\n",
      "[0.50622493 0.49377504]\n",
      "[0.32507023 0.6749298 ]\n",
      "[0.5892014 0.4107986]\n",
      "[0.07678387 0.92321616]\n",
      "[0.90289587 0.09710408]\n",
      "[0.2893693 0.7106307]\n",
      "[0.9084839  0.09151606]\n",
      "[0.05182065 0.94817936]\n",
      "[0.9053865  0.09461349]\n",
      "[0.12029052 0.8797095 ]\n",
      "[0.9050366  0.09496339]\n",
      "[0.16058014 0.83941984]\n",
      "[0.72076344 0.27923658]\n",
      "[0.0665645  0.93343544]\n",
      "[0.73734075 0.26265925]\n",
      "[0.21112554 0.7888744 ]\n",
      "[0.8927972  0.10720281]\n",
      "[0.0665645  0.93343544]\n",
      "[0.8927972  0.10720281]\n",
      "[0.0543643  0.94563574]\n",
      "[0.46431562 0.53568435]\n",
      "[0.0543643  0.94563574]\n",
      "[0.9074617  0.09253827]\n",
      "[0.2893693 0.7106307]\n",
      "[0.90858823 0.09141176]\n",
      "[0.04706734 0.95293266]\n",
      "[0.8927972  0.10720281]\n",
      "[0.19748384 0.8025162 ]\n",
      "[0.9050366  0.09496339]\n",
      "[0.10362651 0.89637345]\n",
      "[0.9084839  0.09151606]\n",
      "[0.0665645  0.93343544]\n",
      "[0.90788287 0.09211718]\n",
      "[0.42290425 0.5770958 ]\n",
      "[0.87280095 0.12719905]\n",
      "[0.16058014 0.83941984]\n",
      "[0.9067746  0.09322543]\n",
      "[0.0543643  0.94563574]\n",
      "[0.5271838  0.47281626]\n",
      "[0.22544488 0.7745551 ]\n",
      "[0.56874293 0.43125707]\n",
      "[0.38254866 0.61745137]\n",
      "[0.7035605 0.2964395]\n",
      "[0.0543643  0.94563574]\n",
      "[0.90362185 0.09637818]\n",
      "[0.42290425 0.5770958 ]\n",
      "[0.5892014 0.4107986]\n",
      "[0.40256143 0.5974385 ]\n",
      "[0.9081443  0.09185565]\n",
      "[0.09608483 0.9039152 ]\n",
      "[0.66739553 0.3326045 ]\n",
      "[0.05980885 0.94019115]\n",
      "[0.90468556 0.09531442]\n",
      "[0.30693066 0.69306934]\n",
      "[0.9061308  0.09386922]\n",
      "[0.07124831 0.9287517 ]\n",
      "[0.56874293 0.43125707]\n",
      "[0.3069306  0.69306934]\n",
      "[0.76853806 0.23146193]\n",
      "[0.07124831 0.9287517 ]\n",
      "[0.90289587 0.09710408]\n",
      "[0.0827338  0.91726613]\n",
      "[0.89832485 0.10167512]\n",
      "[0.0827338  0.91726613]\n",
      "[0.64850813 0.3514919 ]\n",
      "[0.34375012 0.6562499 ]\n",
      "[0.8558617  0.14413828]\n",
      "[0.3629263 0.6370737]\n",
      "[0.6857598 0.3142402]\n",
      "[0.22544488 0.7745551 ]\n",
      "[0.66739553 0.3326045 ]\n",
      "[0.30693066 0.69306934]\n",
      "[0.90289587 0.09710408]\n",
      "[0.34375012 0.6562499 ]\n",
      "[0.7035605 0.2964395]\n",
      "[0.05182064 0.94817936]\n",
      "[0.50622493 0.49377504]\n",
      "[0.10362648 0.89637345]\n",
      "[0.90289587 0.09710408]\n",
      "[0.19748384 0.8025162 ]\n",
      "[0.44351175 0.5564883 ]\n",
      "[0.05702526 0.94297475]\n",
      "[0.90711874 0.09288128]\n",
      "[0.34375012 0.6562499 ]\n",
      "[0.9032597  0.09674034]\n",
      "[0.25610146 0.7438986 ]\n",
      "[0.64850813 0.35149196]\n",
      "[0.07124831 0.9287517 ]\n",
      "[0.90362185 0.09637818]\n",
      "[0.10362651 0.89637345]\n",
      "[0.48524427 0.5147557 ]\n",
      "[0.04706734 0.95293266]\n",
      "[0.78313255 0.21686749]\n",
      "[0.0827338  0.91726613]\n",
      "[0.90858823 0.09141176]\n",
      "[0.27241775 0.7275823 ]\n",
      "[0.72076344 0.2792366 ]\n",
      "[0.0960848 0.9039152]\n",
      "[0.9057352  0.09426474]\n",
      "[0.04938981 0.95061016]\n",
      "[0.7035605 0.2964395]\n",
      "[0.14958508 0.850415  ]\n",
      "[0.90433335 0.09566667]\n",
      "[0.0629392  0.93706083]\n",
      "[0.62914413 0.3708558 ]\n",
      "[0.22544488 0.7745551 ]\n",
      "[0.9064293  0.09357072]\n",
      "[0.0543643  0.94563574]\n",
      "[0.9074617  0.09253827]\n",
      "[0.19748384 0.8025162 ]\n",
      "[0.8798997  0.12010036]\n",
      "[0.14958508 0.850415  ]\n",
      "[0.9032597  0.09674034]\n",
      "[0.07124831 0.9287517 ]\n",
      "[0.56874293 0.43125707]\n",
      "[0.07124831 0.9287517 ]\n",
      "[0.46431562 0.5356844 ]\n",
      "[0.3069306  0.69306934]\n",
      "[0.88658816 0.11341181]\n",
      "[0.14958508 0.850415  ]\n",
      "[0.90468556 0.09531442]\n",
      "[0.34375012 0.6562499 ]\n",
      "[0.9030451 0.0969549]\n",
      "[0.0665645  0.93343544]\n",
      "[0.44351175 0.5564883 ]\n",
      "[0.17221968 0.8277803 ]\n",
      "[0.62914413 0.3708558 ]\n",
      "[0.24043939 0.75956064]\n",
      "[0.87280095 0.12719905]\n",
      "[0.19748384 0.8025162 ]\n",
      "[0.8798997  0.12010036]\n",
      "[0.0629392  0.93706083]\n",
      "[0.86475    0.13524997]\n",
      "[0.10362651 0.89637345]\n",
      "[0.609356 0.390644]\n",
      "[0.11168712 0.88831294]\n",
      "[0.9053865  0.09461349]\n",
      "[0.05702525 0.94297475]\n",
      "[0.9050366  0.09496339]\n",
      "[0.25610146 0.7438986 ]\n",
      "[0.7970498  0.20295022]\n",
      "[0.25610146 0.7438986 ]\n",
      "[0.609356 0.390644]\n",
      "[0.2893693 0.7106307]\n",
      "[0.8927972  0.10720281]\n",
      "[0.13921808 0.8607819 ]\n",
      "[0.54804707 0.45195296]\n",
      "[0.40256143 0.5974385 ]\n",
      "[0.48524427 0.5147557 ]\n",
      "[0.2893693 0.7106307]\n",
      "[0.8798997  0.12010036]\n",
      "[0.18451743 0.81548256]\n",
      "[0.90362185 0.09637818]\n",
      "[0.2893693 0.7106307]\n",
      "[0.609356 0.390644]\n",
      "[0.25610146 0.7438986 ]\n",
      "[0.50622493 0.49377504]\n",
      "[0.24043939 0.75956064]\n",
      "[0.8347647  0.16523536]\n",
      "[0.0543643  0.94563574]\n",
      "[0.90398    0.09602005]\n",
      "[0.07678387 0.92321616]\n",
      "[0.62914413 0.3708558 ]\n",
      "[0.04706734 0.95293266]\n",
      "[0.9074617  0.09253827]\n",
      "[0.05702526 0.94297475]\n",
      "[0.8558617  0.14413828]\n",
      "[0.0543643  0.94563574]\n",
      "[0.54804707 0.45195296]\n",
      "[0.32507023 0.6749298 ]\n",
      "[0.88658816 0.11341181]\n",
      "[0.19748384 0.8025162 ]\n",
      "[0.72076344 0.27923658]\n",
      "[0.34375012 0.6562499 ]\n",
      "[0.90468556 0.09531442]\n",
      "[0.04938981 0.95061016]\n",
      "[0.9032597  0.09674034]\n",
      "[0.07124831 0.9287517 ]\n",
      "[0.90468556 0.09531442]\n",
      "[0.0629392  0.93706083]\n",
      "[0.78313255 0.21686749]\n",
      "[0.22544488 0.7745551 ]\n",
      "[0.5892014 0.4107986]\n",
      "[0.05980885 0.94019115]\n",
      "[0.46431562 0.53568435]\n",
      "[0.05702526 0.94297475]\n",
      "[0.90788287 0.09211718]\n",
      "[0.40256143 0.5974385 ]\n",
      "[0.9064293  0.09357074]\n",
      "[0.32507023 0.6749298 ]\n",
      "[0.9053865  0.09461349]\n",
      "[0.12946011 0.8705399 ]\n",
      "[0.90711874 0.09288128]\n",
      "[0.30693066 0.69306934]\n",
      "[0.48524427 0.5147557 ]\n",
      "[0.11168712 0.88831294]\n",
      "[0.9074617  0.09253827]\n",
      "[0.0960848 0.9039152]\n",
      "[0.64850813 0.3514919 ]\n",
      "[0.18451743 0.81548256]\n",
      "[0.66739553 0.3326045 ]\n",
      "[0.0543643  0.94563574]\n",
      "[0.7035605 0.2964395]\n",
      "[0.0543643  0.94563574]\n",
      "[0.9057352  0.09426474]\n",
      "[0.24043937 0.75956064]\n",
      "[0.609356 0.390644]\n",
      "[0.18451741 0.81548256]\n",
      "[0.5271838  0.47281626]\n",
      "[0.27241775 0.7275823 ]\n",
      "[0.76853806 0.23146193]\n",
      "[0.08910024 0.91089976]\n",
      "[0.7970498  0.20295022]\n",
      "[0.24043937 0.75956064]\n",
      "[0.50622493 0.49377504]\n",
      "[0.04938981 0.95061016]\n",
      "[0.8347647  0.16523536]\n",
      "[0.22544488 0.77455515]\n"
     ]
    }
   ],
   "source": [
    "# # Prediction\n",
    "predictions = model.predict(scaled_test_samples, batch_size = 10, verbose = 0)\n",
    "\n",
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size = 10, verbose = 0)\n",
    "\n",
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Confusion Matrix # #\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[188  22]\n",
      " [ 10 200]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAEYCAYAAAAzhB+DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XecU1X6x/HPd0CaNJEiFkRRrKso\nWFZFsaEoiutasCCKXbGsva3dn65gWde2uhYExV6xorv2ikhdseuKIFJsKCrg8/vjnGCImUwymZnc\nzDxvX3lNcnJz7zMj88y5p8rMcM45l7+KUgfgnHPlxhOnc84VyBOnc84VyBOnc84VyBOnc84VyBOn\nc84VyBOnSyRJzSU9JulbSfcVcZ4DJD1Tk7GVgqQnJQ0udRwu8MTpiiJpf0njJM2XNDP+gm9VA6fe\nC+gELG9me1f3JGZ2p5n1rYF4liKpjyST9GBG+Yax/Pk8z3O+pFFVHWdm/cxsRDXDdTXME6erNkkn\nAVcD/0dIcl2A64EBNXD6VYH3zWxRDZyrtswGtpC0fFrZYOD9mrqAAv89TRoz84c/Cn4AbYD5wN45\njmlKSKwz4uNqoGl8rw8wHTgZ+AqYCRwS37sA+AVYGK9xKHA+MCrt3F0BAxrH1wcDHwPfA58AB6SV\nv5z2uS2At4Bv49ct0t57HrgIeCWe5xmgfSXfWyr+G4FjY1mjWHYu8HzasX8HPge+A94GesfynTO+\nz4lpcVwS41gArBHLDovv3wDcn3b+vwHPASr1v4uG8vC/ZK66/gg0Ax7KcczZwOZAD2BDYFPgnLT3\nVyAk4JUIyfE6ScuZ2XmEWuw9ZtbSzG7JFYikZYFrgH5m1oqQHCdkOa4d8Hg8dnngSuDxjBrj/sAh\nQEegCXBKrmsDdwAHxec7AVMJfyTSvUX4GbQD7gLuk9TMzJ7K+D43TPvMIOAIoBXwWcb5TgY2kHSw\npN6En91gi1nU1T5PnK66lgfmWO5b6QOAC83sKzObTahJDkp7f2F8f6GZPUGoda1VzXh+BdaX1NzM\nZprZ1CzH7Ap8YGYjzWyRmY0GpgG7pR1zm5m9b2YLgHsJCa9SZvYq0E7SWoQEekeWY0aZ2dx4zSsI\nNfGqvs/bzWxq/MzCjPP9CBxISPyjgOPMbHoV53M1yBOnq665QHtJjXMcsyJL15Y+i2VLzpGReH8E\nWhYaiJn9AOwLHAXMlPS4pLXziCcV00ppr7+sRjwjgaHAtmSpgUs6WdK7cYTAN4Radvsqzvl5rjfN\n7E1C04QICd7VIU+crrpeA34C9shxzAxCJ09KF35/G5uvH4AWaa9XSH/TzJ42sx2BzoRa5M15xJOK\n6YtqxpQyEjgGeCLWBpeIt9KnA/sAy5lZW0L7qlKhV3LOnLfdko4l1FxnAKdVP3RXHZ44XbWY2beE\nTpDrJO0hqYWkZST1k3R5PGw0cI6kDpLax+OrHHpTiQnA1pK6SGoDnJl6Q1InSbvHts6fCbf8i7Oc\n4wmgexxC1VjSvsC6wJhqxgSAmX0CbENo083UClhE6IFvLOlcoHXa+7OAroX0nEvqDlxMuF0fBJwm\nKWeTgqtZnjhdtZnZlcBJhA6f2YTby6HAw/GQi4FxwCRgMjA+llXnWmOBe+K53mbpZFdB6DCZAcwj\nJLFjspxjLtA/HjuXUFPrb2ZzqhNTxrlfNrNstemngScJQ5Q+I9TS02/DU4P750oaX9V1YtPIKOBv\nZjbRzD4AzgJGSmpazPfg8ifviHPOucJ4jdM55wrkidM5V29IWkXSf+IohqmSTojl7SSNlfRB/Lpc\nLJekayR9KGmSpI3zuY4nTudcfbIIONnM1iFMvjhW0rrAGcBzZrYmYZbVGfH4fsCa8XEEYVZWlTxx\nOufqjTj5YXx8/j3wLmGc7gAgtUjKCH4bRjcAuMOC14G2kjpXdZ1cg5ddgmmZZU3N2pY6jLK3wZor\nVH2Qy8vEd8bPMbMOxZyjUetVzRYtyHmMLZg9lTA6IeUmM7sp8zhJXYGNgDeATmY2E0JyldQxHrYS\nS49ymB7LZuaKwRNnmVKztjTtdXSpwyh7Yx89vdQh1BsdWzfJnJVVMFu0gKZr7ZPzmJ8mXPeTmfXK\ndYyklsADwIlm9p2kSg/NFkZVcXridM4lhwQVjYo8hZYhJM07zSy1XuosSZ1jbbMzYUUuCDXMVdI+\nvjJ5zG7zNk7nXLJUNMr9yEGhankL8G6coJHyKGGtVOLXR9LKD4q965sD36Zu6XPxGqdzLkEExa3b\nvCVhGupkSamlBc8CLgPulXQo8D8gtavAE8AuwIeERV0Oyecinjidc8khirpVN7OXyd5uCbB9luMN\nOLbQ63jidM4liEI7Z8J54nTOJUuRnUN1wROncy5Bim7jrBOeOJ1zyVFkG2dd8cTpnEsQr3E651xh\nBDTyGqdzzhWg+JlDdcETp3MuWXw4knPOFaAG5qrXBU+czrlk8c4h55wrhNc4nXOucN7G6ZxzBZCg\nIvlpKfmNCc65hkXK/ajy47pV0leSpqSV3SNpQnx8mlpyTlJXSQvS3rsxnxCTn9qdcw1L8W2ctwPX\nAnekCsxs39RzSVcA36Yd/5GZ9SjkAp44nXPJUQPDkczsxbhRW5bTS8A+wHbFXMNv1Z1ziSIp5wNo\nL2lc2uOIAk7fG5hlZh+kla0m6R1JL0jqnc9JvMbpnEsMCVRRZTvmnKp2ucxhP2B02uuZQBczmyup\nJ/CwpPXM7LtcJ/HE6ZxLkCW1ypo/s9QY2BPomSozs5+Bn+PztyV9BHQHxuU6lydO51yiVFTUWgvi\nDsA0M5ueKpDUAZhnZoslrQ6sCXxcZYy1FaFzzlVHHm2cVX1+NPAasJak6XFnS4CBLH2bDrA1MEnS\nROB+4Cgzm1fVNbzG6ZxLDEn5tHHmZGb7VVJ+cJayB4AHCr2GJ07nXKLU4q16jfHE6ZxLlNrqHKpJ\nnjidc8mR33CkkvPE6ZxLDNXicKSa5InTOZcoXuN0zrlCyNs4XT1342n96bf5msz+5gd6DbkJgA26\ndeIfJ/WjaZPGLFr8Kyde/RTjps2g9bJNufWsAazSqQ2NG1Vw9T2vM/KpiSX+DpLni+mfM/TIIXw1\n60sqKioYdPBhHHHMcZx/zhk88+QYlmnShK6rrc411/+LNm3bljrcWlEOverJj9Al1sinJjHg9KXH\nE19y5PZcMuIlNj/8X1x02wtccuT2ABy5Ry+mfTaHzQ67mZ1OHMllR+/AMo39n1+mxo0bc8Ell/PK\nuMk8+dzL3HrzDbw37b9ss+32vPjGBF54bTzd1liTv1/5t1KHWitSbZzFDICvC/4v11XbK5P+x7zv\nFixVZhitl20KQJtlmzFz7veh3IyWLZoAsGzzJnz9/QIWLf61bgMuA51W6MwGPTYCoGWrVnRfa21m\nzpjBttvvSOPG4Qax5yabMeOLL0oZZu2Jveq5Hkngt+quRp167TM8dvn+XHrUDlQItj1uBAA3PjSO\n+y/Zh4/vP4FWLZoy6MIHMStxsAn3v88+ZfKkifTstelS5aNH3s6APfcuUVS1z2/VKyHJ4irMqden\nSDq/gM93kjRG0kRJ/5X0RCxfUdL9lXzmeUl5L0Ul6XZJn6Qtqf9qLG8q6dlYtq+k3pKmxtfN8z1/\nPNcektYt5DNJd8SAnpx2/VjW3PcaTrt+LDec2h+AHTdZnUkfzmL1vf7OZofdzFXH70yrWAN1vzd/\n/nyGDNqXiy4bTqvWrZeUXzXsUho1bsxe++5fwuhqmap4JECpUvvPwJ6S2lfz8xcCY81sQzNbFzgD\nwMxmmNleNRUkcKqZ9YiPLWLZRsAysewe4ABgeHy9oPJTZbUHUK8S5wF9N+DhF6cB8MDz79Jr7RUB\nGNRvQx55KZR/PONrPp35DWt1qe7//vpt4cKFDDlwX/68z3703/1PS8rvvvMOnnnqCW741x2Jaeur\naZKoqKjI+UiCUkWxCLgJ+EvmG5JWlfScpEnxa5csn+8MLFkayswmxc92TW3QJKm5pLvjee4BltQG\nJfWV9Jqk8ZLuk9Qyn6AldQRGAT1iDfNIwjL850q6Mx5zqqS34nUvSPvsQbFsoqSRkrYAdgeGxXN1\nk3R8rEFPknR3PjElzcy58+m94aoA9Nm4Kx9+ERaa+XzWd/TZeDUAOi63LN1XaccnM74uWZxJZWac\neOwRdF9rbY4eeuKS8n+PfZprrx7OyHsepEWLFiWMsPbVwOpI2TZrO1/SF2l3kLukvXempA8lvSdp\np3xiLGUb53WE5Zwuzyi/FrjDzEZIGgJcQ6iZZX72HklDgWeB28xsRsYxRwM/mtkGkjYAxgPEWu45\nwA5m9oOk04GTCLXYTMMknROfTzWzAyQdBpxiZv3j+f4IjDGz+yX1JazntynhpuJRSVsDc4GzgS3N\nbI6kdmY2T9Kjqc/Gc50BrGZmP0v63VgThS0CwjYBTdtk/aHWpRHn/InePbrQvk0LPrz3eC66/UWO\nHf44w47rS+NGFfz8yyKGXvE4AJeNfImbTt+dt245AgnOvunfzP2u0Ap6/ffG669y3913ss5667Pt\nlqFl6exzL+Ks007il19+Zu8B/YDQQTT86utKGWqtqYEOoNvJ2KwtusrMhi91rdBUNhBYD1gReFZS\ndzNbnOsCJUucZvadpDuA44H036A/ElZpBhgJZCZWzOxphUVHdwb6Ae9IWj/jsK0JSRczmyRpUizf\nnHB7/Er869WEsHZfNqemklqe+sbHO/F1S0Ii3RC438zmxHgqW+9vEnCnpIeBhzPfNLObCDV1Klqt\nVPKulcEXP5S1fMsjb/ld2cy589nttLtqO6Syt/kft+Sr7375XfkOO/UrQTSlUWwzRK7N2rIYANwd\nV4L/RNKHhIpPZTkBKP1wpKuBQ4FlcxyTNUGY2Twzu8vMBgFvERJlPp8VoX001Xa5rpkdmuW46hBw\nadq51zCzW2J5PoluV0JtuifwtsJS/841GBJUVCjnowhDYzPYrZKWi2UrAZ+nHTM9luVU0sQZa173\nEpJnyquEqjOEjpeXMz8naTtJLeLzVkA34H8Zh70YP0+sjW4Qy18HtpS0RnyvhaTuNfINwdPAkFSb\nqaSVYrvoc8A+kpaP5e3i8d8DrWJZBbCKmf0HOA1oS6ixOteA5DUAvjq7XN5AyBM9CBu0pUb1ZMvE\nVVZyklCjuQIYmvb6eOBWSacCs4FDsnymJ3CtpEWE5P8vM3sro3p+A3BbvEWfALwJYGazJR0MjJbU\nNB57DvB+luukt3FCqMJXysyekbQO8Fr8HzwfONDMpkq6BHhB0mLCrfzBwN3AzZKOJ/yxuEVSG8L/\nzKvM7Jtc13OuPsqjVlnwLpdmNiv1XNLNwJj4cjqwStqhKwOZ/SW/I/NRyGWpotVK1rTX0aUOo+z9\n79HTSx1CvdGxdZO3i9i2F4Dmnbvbaodcm/OYdy/dqcrrxErUGDNbP77ubGYz4/O/AJuZ2UBJ6wF3\nESpFKxLuDtdMbOeQc85lU+wQVYXN2voQbumnA+cBfST1INyGfwocCRDvBu8F/ksYJnlsVUkTPHE6\n55JEed2q51TJZm2/H+rx2/GXAJcUcg1PnM65xBC+HqdzzhWo6CFHdcITp3MuUbzG6ZxzBVANtHHW\nBU+czrlEKYMKpydO51yyeI3TOecK4LfqzjlXsORsyJaLJ07nXKJ4jdM55wqhMu8cktS6svcgLERc\n8+E45xoyUR67XOaqcU4lTIhPz/+p1wZk2wvIOeeKUtY1TjNbpbL3nHOuVpRJr3pedWJJAyWdFZ+v\nLKln7YblnGuIRO5tM/JJqpXscjlM0rS4dcZDqc0QFXbGXZC2++WN+cRZZeKUdC2wLTAoFv0I5HVy\n55wrVIWU85GH2wkbOaYbC6xvZhsQdns4M+29j9L2CTsqrxjzOGYLMzsS+AmW7BPUJJ+TO+dcIWpi\nszYzexGYl1H2jJktii9fJ2yRUW35JM6FcSMxA4gbjv1azEWdc64yFcr9oHqbtaUbAjyZ9no1Se9I\nekFS73xOkM84zuuAB4AOki4A9gEuKDBQ55zLS21s1pYi6WzCFhl3xqKZQBczmxv7bh6WtF5Vwy2r\nTJxmdoekt4EdYtHeZjYl12ecc646ROggqpVzS4OB/sD2FnepNLOfgZ/j87clfQR0B8blOle+M4ca\nAQsJt+vJH53qnCtPEo1qYTiSpJ2B04FtzOzHtPIOwDwzWyxpdWBN4OOqzpdPr/rZwGjC1pkrA3dJ\nOjP3p5xzrnqk3I+qP6/RwGvAWpKmSzoUuBZoBYzNGHa0NTBJ0kTgfuCo2AGeUz41zgOBnqksLekS\n4G3g0jw+65xzeRMUXeMsZJdLM3uA0IdTkHwS52cZxzUmj6qsc84VquzX45R0FaFN80dgqqSn4+u+\nwMt1E55zrqHJc5B7SeWqcaZ6zqcCj6eVv1574TjnGrqyTpxmlrVNwDnnaotYMsg90aps45TUDbgE\nWBdolio3s+61GJdzriFSftMqSy2fMZm3A7cR/hj0A+4F7q7FmJxzDZiknI8kyCdxtjCzpwHM7CMz\nO4ewWpJzztWo1HCkXI8kyGc40s8Kaf4jSUcBXwAdazcs51xDlYzUmFs+ifMvQEvgeEJbZxvC6iLO\nOVejpOIHwNeFfBb5eCM+/Z7fFjN2zrlaUQ6dQ7kGwD9EXIMzGzPbs1Yics41WCLvVd5LKleN89o6\ni8IVbKPunXll7DmlDqPsLbfJ0FKH4NKV+5RLM3uuLgNxzjkoj3UryyFG51wDURPDkSrZ5bKdpLGS\nPohfl4vlknSNpA/jDpgb5xOnJ07nXKLksedQVW7n97tcngE8Z2ZrAs/F1xAm9awZH0cAN+QVY15h\nAJKa5nusc85VR2o4UjE1zmy7XAIDgBHx+Qhgj7TyOyx4HWgrqXNV18hnBfhNJU0GPoivN5T0jyqj\nd865ashjBfjq7HLZycxmAsSvqUk8KwGfpx03PZbllM8A+GsIGxw9HC86UZJPuXTO1TgBjasejlTt\nXS4ruWSmSodhpuSTOCvM7LOMyfWL843KOefypVrarA2YJamzmc2Mt+JfxfLpwCppx60MzKjqZPm0\ncX4uaVPAJDWSdCLwfqFRO+dcPordrK0SjwKD4/PBwCNp5QfF3vXNgW9Tt/S55FPjPJpwu94FmAU8\nG8ucc65GCWhcZI0z7nLZh9AWOh04D7gMuDfuePk/YO94+BPALsCHhG2CDsnnGvnMVf8KGFho8M45\nVx3FzrisZJdLgO2zHGvAsYVeI58V4G8mS2OpmeXTk+Wcc/kTNCrzueopz6Y9bwb8iaW7751zrkbU\nmz2HzOye9NeSRgJjay0i51yDVi/W48xiNWDVmg7EOefqTY1T0tf81sZZQZjKdEbln3DOuWqqDyvA\nx72GNiTsMwTwa+yFcs65GhdWRyp1FFXLGWJMkg+Z2eL48KTpnKtFoqKKRxLkk9vfzHeNOuecK0ZY\nHSn3Iwly7TnU2MwWAVsBh0v6CPiBUJs2M/Nk6pyrceW+59CbwMb8tm6dc87VqtQK8EmXK3EKwMw+\nqqNYnHOu6CmXdSFX4uwg6aTK3jSzK2shHudcA6Z6MOWyEdCS7At9OudcjRPFJU5JawHpsx1XB84F\n2gKHA7Nj+Vlm9kR1r5Mrcc40swure2LnnKuOYmpqZvYe0ANAUiPCGPSHCMvFXWVmw4uPMI82Tuec\nqzuiouY6h7YHPsqyg0XRco2K+t3adc45V5tESEq5HuS/WdtAYHTa66Fx7/RbU/uqV1elidPMMrfX\ndM65Wlch5XwQN2tLe9yUeQ5JTYDdgfti0Q1AN8Jt/EzgimJirM7qSM45VzsUNmyrAf2A8WY2CyD1\nFZYszj6mmJN74nTOJUaxvepp9iPtNj21w2V8+SdgSjEn98TpnEuUYtOmpBbAjsCRacWXS+pBWCLz\n04z3CuaJ0zmXGDVR4zSzH4HlM8oGFXXSDJ44nXMJorJf5MM55+pcGeTNvNbjdK5KRx42hC4rdqRn\nj/WXlM2bN49dd96R9ddZk1133pGvv/66hBEm18qd2vLUTcfzzgPn8Pb9Z3Psfn0AWK51C8bcMJTJ\nj5zLmBuG0rZV8yWfueK0vZjyyHm8ec+Z9Fh75RJFXvNSc9VzPZLAE6erEYMGH8wjY55aqmz45ZfR\nZ7vtmfLuB/TZbnuGX35ZiaJLtkWLf+WMKx9koz9fzDYHDefIfbdm7dVX4JRDduT5N9/jDwMu5Pk3\n3+OUQ/oCsNNW69KtSwfWH3ABQy8ezTVnDSzxd1CzpNyPJPDE6WrEVr23pl27dkuVjXnsEQ4cNBiA\nAwcN5rFHHy5FaIn35ZzvmDBtOgDzf/yZaZ98yYod2tK/zwaMeuwNAEY99ga7bbsBAP232YC7xrwJ\nwJuTP6VNq+as0L51aYKvYanOIa9xugbrq1mz6Ny5MwCdO3dm9ldflTii5OvSuR091lqZt6Z8Ssfl\nW/HlnO+AkFw7tGsFwIod2zL9y9+aPb6Y9Q0rdmxbknhrg6r4LwlqLXFKmp/x+mBJ1xZ4jk8ltc9S\nPkTS5DjvdIqkAbH8Qkk7ZDm+j6S8ZwpI6ippgaQJaY+D4nt7S3pX0n/i69Exjr8U+L21lXRMIZ9x\n9duyzZswevhhnDr8Ab7/4adKj8tW6apP+yjmMeWy5MquV13SysDZwMZm9q2klkAHADM7twYv9ZGZ\n9chSfihwjJn9R9IKwBZmtmo1zt8WOAa4vpggk6xjp07MnDmTzp07M3PmTDp07FjqkBKrceMKRg8/\nnHueHMcj/54IwFdzv2eF9q35cs53rNC+NbPnfQ+EGubKK/y2RsVKndoyc/a3JYm7pgkog50zSnOr\nLmk3SW9IekfSs5I6xfLlJT0Ty/9J9kkEHYHvgfkAZjbfzD6Jn79d0l7x+c6Spkl6Gdgz7drLxtVR\n3orXGVBA3OcSNq+7UdIw4BmgY6yR9pbUTdJTkt6W9JKktePnOkl6SNLE+NgCuAzoFj87TFJnSS/G\n11Mk9S74B5swu/bfnVEjRwAwauQI+u+W94+6wbnxvAN475MvuWbUv5eUPf7CZA7cbTMADtxtM8Y8\nP2lJ+f79NwVg0z905bv5C5bc0pe9KmqbDaHG2VzShLTX7YBH4/OXgc3NzCQdBpwGnAycB7xsZhdK\n2hXItlzURGAW8Imk54AHzeyx9AMkNQNuBrYDPmTpFaHPBv5tZkMktSVsf/ysmf2QcZ1uGfEfF+Pa\nDjjFzMZJug4Yk6qZxniOMrMPJG1GqE1uB1wDvGBmf4qLq7YEzgDWT/vsycDTZnZJPKZF5T/a5Dno\nwP146YXnmTNnDt26rsxfz72AU047gwP324cRt93CKqt04c6776v6RA3QFj1W54D+mzH5/S94/e4z\nADjv2kcZfttYRv1tCIP3+COfz/yaA067BYCnXp7KTlutx9RHz+PHnxZy5PmjShl+jarBueq1qjYT\n54L0W11JBwO94suVgXskdQaaAJ/E8q2JtUMze1zS7wb+mdliSTsDmxDWDL1KUk8zOz/tsLWBT8zs\ng3jtUfyWhPsCu0s6Jb5uBnQB3s24VGW36lnFJoMtgPvSVndpGr9uBxyUih/4Nst6gG8Bt0paBnjY\nzCZkvE9cd/AIgFW6dMk3tDpxx6jRWcuffOa5Oo6k/Lw64WOabzQ063u7HPWPrOV/ueze2gyppJKf\nNkvXq/4P4Foz+wNhsn2ztPeqbOW24E0zu5SwWOmfsx1WyccF/NnMesRHFzPLTJrVUQF8k3beHma2\nTr4fNrMXCX84vgBGpjqjMo65KbUGYYf2HWogZOeSR1LORxKUKnG2ISQIgMFp5S8CBwBI6gf8bpVm\nSStK2jitqAfwWcZh04DVJHWLr/dLe+9p4DjF/wOSNqruN5HOzL4jNB/sHc8rSRvGt58Djo7ljSS1\nJrTTtkr7vlYFvjKzm4FbCHvaO9fg+AD4yp1PuKV9CZiTVn4BsLWk8YRb6v9l+ewywPDY8TMB2Bc4\nIf0AM/uJcEv7eOwcSk+sF8VzTJI0Jb7OJtVxk3ocn8f3dQBwqKSJwFQg1RtyArCtpMnA28B6ZjYX\neCV2BA0D+gATJL1DqEH/PY/rOVfvFJs4FYYxTo6/t+NiWTtJYyV9EL8WtXWG6tP4r4akZ89e9sob\n40odRtlbbpPsbYuucD9NuO5tM+tV9ZGVW/cPG9kdj76Q85hNVm+T8zqSPgV6mdmctLLLgXlmdpmk\nM4DlzOz06sbpM4ecc8mhMI4z16OaBgAj4vMRwB7FhOmJ0zmXLKriUfUulwY8E8dTp97rlNo6I34t\najZG2c0ccs7VZ3kNcp9TRZPAlmY2Q1JHYKykaTUXX+A1TudcYojiO4fMbEb8+hXwELApMCuOGyd+\nLWrFGU+czrlEKWZ1pDilulXqOWF0zhTCrMXU0MfBwCPFxOi36s65RClykY9OwENxmHZj4C4ze0rS\nW8C9kg4lDHPcu5iLeOJ0ziXHbx1A1WJmHwMbZimfS5iiXSM8cTrnEiMsK5eQ6UE5eOJ0ziVK8tOm\nJ07nXMIkZSGPXDxxOucSpRxWgPfE6ZxLFk+czjmXP8k7h5xzrmDJT5ueOJ1ziZKcVd5z8cTpnEuU\nMsibnjidc8mRWuQj6TxxOucSpaqFPJLAE6dzLlHKYRynLyvnnEsOFbc9sKRVJP1H0ruSpko6IZaf\nL+mLtM0XdykmTK9xOucSowbaOBcBJ5vZ+Lgu59uSxsb3rjKz4UWGCHjidM4lTDG36nE/odTeQt9L\nehdYqWYi+43fqjvnEqWYFeCXOo/UFdgIeCMWDZU0SdKtxe6r7onTOZcoeew5VNUul0hqCTwAnGhm\n3wE3AN2AHoQa6RXFxOi36s65xMhzQ7acu1xKWoaQNO80swcBzGxW2vs3A2OKidNrnM65RCmyV13A\nLcC7ZnZlWnnntMP+RNjArdq8xumcS5Qih3FuCQwCJkuaEMvOAvaT1AMw4FPgyGIu4onTOZcgKmpZ\nOTN7mey594lqnzQLT5zOucTwuerOOVcNnjidc64QvgK8c84VRvgK8M45VzBfAd455wpUBnnTE6dz\nLlk8cTrnXIHKYQV4mVmpY3DVIGk28Fmp46hCe2BOqYOoJ8rhZ7mqmXUo5gSSniJ8r7nMMbOdi7lO\nsTxxulojaVyuxRhc/vxnmSwMeCiXAAAQoklEQVS+yIdzzhXIE6dzzhXIE6erTTeVOoB6xH+WCeJt\nnM45VyCvcTrnXIE8cTrnXIE8cTrXwKkcJocnjCdOV1b8l7xmSZLFjg5J60pqVeqYyoEnTlc2Mn7J\nB0vau9Qxlbu0n+dJwHWAJ848eOJ0ZSPtl/w04Ajg3dJGVD9IGggMBAaY2QxJK0taudRxJZkPR3KJ\nJ6nCzH6Nz1cG/mVmO0taDtgC6GFml5Q0yDIiqbWZfRefLw9sRNgd8jOgC7AHMBkYbmaTSxZogvnq\nSC7RYnJsB3wkaTNgFtBF0gjCHdP3wK6SGpvZBSUMtSxIWgbYS1IL4GtgU2AM4Rb9QOAK4Kn43PND\nJfwH45JuXaCvpI7ANma2bry1HADcZ2bTYltnL0mNzGxxSaNNODNbKOkRYDzQDOhqZgskvQr8bGaL\nJO0B9AauLGWsSeZtnC6RUr3nZvYK0BkYDFwWyyaZ2UUxaQ4FzgXu8KRZuYzRCMsCrwIfAycDmNkP\nQCNJ/Qk/z4PM7NO6jrNceI3TJU5G7/lmwM3A58DGkuYBz8VaUhegL7CfmU0tXcTJl/bzPA6YDxxF\nqHHeK6m5mZ0N9CLcsvczs1klC7YMeOeQS6xYm9wDONDMvpR0OtANGAX0AH4E7jSzBSUMs2xIOgQY\nCvw5VZuU1B24C5gHtAX2NrOkL5Bdcp44XSJJ6g1cA+xiZjPTyk8FVgP6AAPNbFJpIiwv8Vb9FuAB\nM3tcUhMz+yW+1xY4CHjSzD4oZZzlwm/VXaKk3aa3Byab2cz4S9/YzBaa2TBJzYHmZjavtNEmV3pz\nB4RbdUm/Am1iUWp41zbAODO7pgRhli3vHHIll9Fx0Tx+nQS0lrStBQslDZF0opkt8KRZuTjuNdWm\n2U/SlpLWIjRx/F1Sz/jeQEKtvmXpoi1PfqvuSiqjI+hwwmDs94EpwMaEHvWvCZ1DJwD7mtl7JQo3\n8TJuwYcC+wMjgGHAKsB+wKGEWVdrAEf6IPfCeeJ0JSNpBTP7Mj4/GDgMOAZ4DPhb/Lo2sC9hoPst\nZjalNNEmn6S+QHfgX4QZQFcDfyZ0CO1I6C1fLGkFQIQ7+C9LFW8588TpSkLSAOD/gE2ABcDFwGhg\nQ+AQwi/5QknNzOyn9GmX7vckrQE8QailNyLMtjoc+AnYDNgrDuE6mDCc6/NSxVofeOeQq3OSmgFb\nAf8AehKmUX4K3AHMNbMd4nEnEYbJ3O5Js3KSViE0ZSwgTJlsDBxPmMf/BzNbPh53AOE2/ckShVpv\neOJ0dUrSVoTOiE8I7W9tgZ2BicBMwoDspoTxmwcR2uRcJSTtAlxtZt0lvUb4mV5sZj9I+jPwtKS7\ngS+ArYEhPri9eN6r7uqMpF7AKDN7CngbWA4YBzQ1szeBuwm37k8Slo0bZGa+dFwlJDUGtgPOlbQR\n4RZ9KDBQ0hAzm0tY9eh54E3CDCvvCKoB3sbp6oykzQm9u08TxmleBRxJqIHeYmYT49CkjsBPZvZt\nyYJNOEkdzGy2pKOAo4FfgP5mNivWQi8FrjSzESUNtJ7yGqerdZK2kNTOzF4n9I6fCLwYp/ZdASwC\nBknaEsDMZnnSrFwqMUpqArxD+D3+Kr7XyMyeAE4BLpK0b+kirb88cbpaFYfIjARWj0XjgZuA/SVt\nGW8nLwRaA/2ApiUJtExI2pFQm7w7jtf8FPgjoY34GsJwJMxsLHAw8FZJAq3n/Fbd1RpJ/QjDjE40\ns5finOiFhMU5TiS0z11kZm/G95p6x0XlJO0E3AbsYGb/ldSN0IF2gZn9KukqoAPwN2/LrF1e43S1\nQtI6hIVwb4pJcyXCgPat4kyhUYS2zmGSepnZN540q9SJMBLm63ibfhfwbWqolpn9hbBk3EnxfVdL\nfDiSqy3fAm8AjWNN6VzCEnBPA8SOjVGAEcZxuiqY2R1xoY7/EJo0zjazu1Lvxw6jo+LXX0oWaAPg\nt+quxqXmn0vqCpxBGIj9pJmdnnbMbsDrZja7NFGWL0mDCKvh72JmE2PZQcBOwFFm9n0p42sI/Fbd\n1biYNBUXy70QeBn4RtL6AJL2IXRktKn8LK4yZjYSOBMYKekPsQPuBOD/PGnWDa9xuhqXVuOsiJ0W\nXQm/6B8Slo3rDwz2we2Vy1xPM5YtNV9f0oHADcBsYFf/edYdT5yuaNl+yVPlhH9jv0paldDDvg4h\nafoeQZXIWGqvJ2ER5zcqOXYfYIqZ/bcuY2zoPHG6omT8kg8B1gRmAM+nhsSk1UA7QRjgXrKAEyzz\nD5CkE4C9CGM1uxP2CppeovBcGm/jdEVJS5rHAwcS2jP3J9yOLzkm3mbO8qSZU2sICTTOouprZr2B\nCYQZVzNSB0pqVJoQHXjidNUkaTVJy8XnjYGVCIvldiUMRbpcUjNJbQB8WbjcFLY6vivOpjLCSlFP\nShpG6C3vF5s89gIw30O+pDxxuoLE2tCywD8JA63bmdkiwvJw44CdzGzn+It9ALBVbOt0uf0APAWc\nGleR+gHYm7Ba1M5xUeeDgNMkdSxhnA5PnK5wMrMfgEFAL+CwmBhvI9Q0nwCQNJiw0MR72TqOXJD6\noxLn7H8O/AxcQBh9cBbh9v2vcTrlycAhZvZVicJ1kXcOubxldATtSZgn3Zewkvv1hG0bTgO+BFYl\nrKfpved5iB1BfwbuJfxBag8cS0icG8fXj5jZhyUL0i3hidPlJSNp7koYWtQbWI+wWs+zwHDCNN42\nwC+xFuWyUNiu91cz+yDWOm8hrJ85RVJnYDBh1aNzU7ODXHL4rbqrkqQNCDsmpiwDTDWz+XF84TGE\n1Y6uAJqY2UxPmpWLC3DsCcyV1Dr+QWpLWNQZM5tJmOe/AnCmpObeTpwsnjhdPqYA/xcXJG4CTCUs\n3rGOwi6U04DbCWM4XQ5xKbgmZnYpYZ/zCyWtRmgP7iTp7HhoW+Al4DgzW+DtxMnit+quUpJ2ALqZ\n2T8lVRCWMWsD7AKcTrhNHx8P70P4Jf9fKWItB3Hl9gsJtfPXCUO4ziWMz3w4HnY9YbWodYA9vI04\nmTxxuqziIsTDCO2W91jYk3tZQkdQS2BfYHdgI8Kslot92l/l4kIcVwInmdkzaeUrAH8FviG0c35K\nuEVf6CtHJZcnTvc7knoQbr0PN7O3Mt5rBvydsEPlAXF8YRNf/7FycZbPhcB4M3sgThxYFVifsPDJ\nBMIycY2B63yxjuTzhYxdNga8ZGZvxS0t9iEMO1pEuJU8BfgX4dZ971juKmFmiyUtJox5nUxIoi2A\ndoTxmtcTRimcCcwpWaAub17jdL8jaWNCDWgscAhhD/SPCB0WaxIS6UJg+dgD7CqRtsBJe+BvwLbA\nM4QN7N4kTFPd2cyOl9Q4zsJyCeeJ02UVB7ivQRh5MSKVICWNBU7xsYXVI2l1M/s47fXJhGmVg4BF\n3nteHvxW3S0lVUMyswezvDcQWJ4wM8hVQtJWhE3pLouvU9MqLZU0Y1vxfoSVpA40s4WlitcVzhNn\nA5e5BmS8rWyUvvqOpNUJbZzHAPv70nBV+go4VtKPZnZNlpXcWxH2kD8GXwm/LPmtegOWMY1yTcIi\nHV/HnvIlyVPSH4CBwCj/Ja9cxor3BwGXA9ea2cVZjm0JNPchR+XJE6dD0jHAEGAaYTbLrmY2PyN5\n+pCjPMVFnTcFPiFsojbMzC6K72XdZsSVF79Vb4AktbK4G6Kk3sARwB6EGSzDgFckbR4HvafaPD1p\nViHWONsT2i6PMbN3JN0CvBx/jhd60qwffK56AxPnSv9V0iax6GvgVQtb+S40sxMIc9P3gN+2xnDZ\npS++EX9W84D/As3idiGfAicB50s6rDRRuprmibPhaQP8CvwpzhCaB+wkqX9akpxFWAHJ5ZDRRrxW\nXOloMeEW/QxC7RNgPnAt8HxJAnU1zts4GwhJbc3sm/h8PUJnT3PCXPQ1gIcIy8I1IiyoO9DM3i9R\nuGVF0lDC7fkrwI9mdr6k4YQ5/D8SFkPZ3cw+KWGYrgZ54mwA4ipH1wNPAqOA6YRplUcBTQlzz1cg\nbAq2HGHAu/eeV0LScmb2dXy+H2FY0QDCIh4bE5o+jpK0BtAF+MSTZv3it+oNwxzCL/AhwGbAi4Tt\ne1sSVuU5FZhrZn8zszM8aVZO0qqEHTy3j0XfEObrDwRWJExHXUfSSGC6mf3bk2b9473qDYCZTYjz\nz18AviMMZt8W6Elo8+wBVEg6ndBB5LchlWtEaMPcU9J8M3tSUnPCNhdHmdnHkt4HliUs4jEjx7lc\nmfJb9QYk9qQ/C5xgZrfH5c42JCTSR7ymmZ848+dkQtvw9Wb2qqRnCIsR/0IYkXCID26vvzxxNjAx\neT4DnG1m15c6nnIQb8u7m9kN8XVHwh+gaYThXFcTOtr+QqhlnuWLoNRvnjgbIEk9gbeAw8zs1lLH\nk3Txj83rhHn690h6mdDJNgo4HFgb+KeZjfcZVg2DJ84GStJGhKEz75U6lnIgqRdhfdLFhL2VRsfy\nboSOoQ7AmWa2oHRRurriidO5PMXFTl4Ejjazu+PMoF9jT/v3ZjavxCG6OuK96s7lycwmx03XnokT\nCm6M5Z+VODRXxzxxOleAuA/TDsBbkn42s9tKHZOre36r7lw1eBtxw+aJ0znnCuRTLp1zrkCeOJ1z\nrkCeOJ1zrkCeOJ1zrkCeOJ1zrkCeOF2dkrRY0gRJUyTdJ6lFEefqI2lMfL67pDNyHNs27uZZ6DXO\nl3RKvuUZx9wuaa8CrtVV0pRCY3R1zxOnq2sLzKyHma1PWILtqPQ3FRT879LMHjWzy3Ic0pawUrtz\nRfPE6UrpJWCNWNN6V9L1wHhgFUl9Jb0maXysmbYEkLSzpGlxhaI9UyeSdLCka+PzTpIekjQxPrYA\nLgO6xdrusHjcqZLekjRJ0gVp5zpb0nuSngXWquqbkHR4PM9ESQ9k1KJ3kPSSpPcl9Y/HN5I0LO3a\nRxb7g3R1yxOnKwlJjYF+wORYtBZwh5ltBPwAnAPsYGYbA+OAkyQ1A24GdgN6E/ZJyuYa4AUz25Cw\nB9BUwq6TH8Xa7qlxzvmawKaEFfB7Sto6Lrk3ENiIkJg3yXqFpT1oZpvE670LHJr2XldgG2BX4Mb4\nPRwKfGtmm8TzHy5ptTyu4xLC56q7utZc0oT4/CXgFsJePZ+Z2euxfHNgXeCVuG15E+A1wrqXn5jZ\nBwCSRgFHZLnGdsBBAHG73m8lLZdxTN/4eCe+bklIpK2Ah8zsx3iNR/P4ntaXdDGhOaAl8HTae/ea\n2a/AB5I+jt9DX2CDtPbPNvHavqtomfDE6eraAjPrkV4Qk+MP6UXAWDPbL+O4HoTdOWuCgEvN7J8Z\n1zixGte4HdjDzCZKOhjok/Ze5rksXvs4M0tPsEjqWuB1XYn4rbpLoteBLeP2ukhqIak7YauK1eLi\nwRD2Ms/mOeDo+NlGkloD3xNqkylPA0PS2k5XiltivAj8SVLzuLfQbnnE2wqYKWkZ4ICM9/aWVBFj\nXh14L1776Hg8krpLWjaP67iE8BqnSxwzmx1rbqMlNY3F55jZ+5KOAB6XNAd4GVg/yylOAG6SdChh\nxfajzew1Sa/E4T5PxnbOdYDXYo13PnBg3P7iHmAC8BmhOaEqfwXeiMdPZukE/R5hd9FOhF0wf5L0\nL0Lb53iFi88mbPDmyoSvjuSccwXyW3XnnCuQJ07nnCuQJ07nnCuQJ07nnCuQJ07nnCuQJ07nnCuQ\nJ07nnCvQ/wMddZL6uyeZnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2276d192080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = [\"No Side Effects\", \"Had Side Effects\"]\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Saving Models # #\n",
    "\n",
    "#Architecture, weights from training, optimizer, learning rate\n",
    "model.save(\"Medical_trail_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "new_model = load_model(\"Medical_trail_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.4467648 ,  0.55861163,  0.02231337, -0.20649669, -0.15817091,\n",
       "         -0.1211707 , -0.3206095 , -0.05006899,  0.53346485,  0.48699513,\n",
       "          0.40459692, -0.03364277, -0.02168095,  0.06766415, -0.57358295,\n",
       "          0.3198928 ]], dtype=float32),\n",
       " array([-0.08458918, -0.12177816,  0.13491672,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.1775527 , -0.10947301, -0.09553168,\n",
       "        -0.09150341,  0.        ,  0.        ,  0.18242377,  0.        ,\n",
       "         0.19492827], dtype=float32),\n",
       " array([[-1.27698526e-01, -2.12632164e-01, -3.34581494e-01,\n",
       "         -5.93382120e-02, -3.08472693e-01,  2.06790194e-02,\n",
       "          1.89073235e-01, -1.15034385e-02, -3.30862373e-01,\n",
       "          1.61687732e-01, -3.13449472e-01,  5.60737699e-02,\n",
       "          4.85804200e-01, -3.83439630e-01, -1.35837138e-01,\n",
       "          2.06329316e-01,  2.86930233e-01, -3.53997350e-02,\n",
       "          4.26320106e-01, -4.30193126e-01, -1.28859699e-01,\n",
       "         -2.77797580e-02,  2.35945806e-01,  2.71027714e-01,\n",
       "         -3.48742336e-01,  2.27265880e-02,  5.01309633e-01,\n",
       "          2.53216714e-01, -1.58546612e-01, -2.11568400e-01,\n",
       "          9.52298269e-02, -3.03260475e-01],\n",
       "        [ 9.92266983e-02, -3.85421306e-01,  1.31408900e-01,\n",
       "          1.65279806e-02, -1.58616900e-03,  7.06044957e-02,\n",
       "         -1.99745506e-01, -1.66289121e-01, -7.88982213e-02,\n",
       "          3.12759906e-01,  7.78192580e-02, -4.38420009e-03,\n",
       "          1.94763362e-01, -3.92563909e-01,  4.24450696e-01,\n",
       "          2.48016402e-01, -1.17666554e-02, -1.06794298e-01,\n",
       "          3.54763478e-01, -1.17087811e-02, -6.82529435e-02,\n",
       "          3.17361802e-01,  3.29347432e-01,  2.07578495e-01,\n",
       "          2.08103940e-01,  1.09582193e-01, -7.22262682e-03,\n",
       "         -2.62081355e-01,  1.18550003e-01, -3.12429070e-01,\n",
       "          2.38981545e-01, -2.14010730e-01],\n",
       "        [-1.16602361e-01,  4.60500687e-01, -2.51799256e-01,\n",
       "         -2.59107858e-01,  4.58190143e-02, -6.42898008e-02,\n",
       "          3.44962835e-01,  1.39207557e-01, -5.99083304e-03,\n",
       "         -2.69329667e-01, -8.13333988e-02,  2.44638309e-01,\n",
       "         -1.32488146e-01,  1.84141830e-01,  1.89848512e-01,\n",
       "         -1.69015869e-01, -9.85888541e-02, -5.82493842e-02,\n",
       "          1.39722675e-01, -3.21102003e-03,  3.37680101e-01,\n",
       "         -1.62128806e-02,  1.30301580e-01, -1.19439885e-01,\n",
       "         -2.76135534e-01,  1.42254561e-01, -2.39138052e-01,\n",
       "         -5.87744154e-02, -2.49536902e-01,  3.51466499e-02,\n",
       "         -2.02791467e-01, -8.30554962e-02],\n",
       "        [-1.86690047e-01,  7.59807229e-02,  1.94746822e-01,\n",
       "          2.86476105e-01,  4.43214476e-02,  3.18150312e-01,\n",
       "         -4.86757457e-02, -1.53194934e-01,  2.87933022e-01,\n",
       "         -1.56199634e-02,  8.65482092e-02,  2.34782696e-03,\n",
       "          1.26214474e-01,  2.83536762e-01,  2.00717002e-01,\n",
       "          2.99748480e-02, -3.78897488e-02,  7.50230849e-02,\n",
       "          3.39002281e-01, -2.74493486e-01,  2.35047489e-01,\n",
       "          4.25011218e-02,  2.24474102e-01, -1.68325916e-01,\n",
       "          1.88420266e-01, -1.79964349e-01,  2.21510679e-01,\n",
       "         -1.29275426e-01,  3.24833840e-01, -1.77365065e-01,\n",
       "          1.41270846e-01, -2.10773513e-01],\n",
       "        [ 1.23273045e-01,  3.32947701e-01,  6.94496632e-02,\n",
       "         -9.02774632e-02, -8.05770159e-02,  2.31739134e-01,\n",
       "         -2.21922204e-01,  3.29597563e-01, -1.08747467e-01,\n",
       "         -1.94933221e-01, -2.34184861e-02,  3.14160019e-01,\n",
       "         -3.42282385e-01,  6.92117810e-02, -1.81479603e-01,\n",
       "         -3.04602772e-01, -3.13757837e-01,  2.42833346e-01,\n",
       "         -1.75322115e-01,  2.22047538e-01,  4.65344191e-02,\n",
       "          1.48290068e-01,  2.35418528e-01, -2.53415674e-01,\n",
       "          1.70448095e-01, -3.32270831e-01, -2.87015826e-01,\n",
       "          1.09686822e-01, -2.87937313e-01,  2.00351804e-01,\n",
       "         -3.24949831e-01, -2.19342649e-01],\n",
       "        [ 3.00093204e-01, -1.65227443e-01,  2.04865187e-01,\n",
       "         -8.59583318e-02,  2.73135096e-01,  1.18606716e-01,\n",
       "         -1.97387084e-01,  8.03875923e-03, -1.68365270e-01,\n",
       "         -3.18998367e-01,  2.41373926e-01,  2.70298213e-01,\n",
       "          1.87500268e-01, -1.08421251e-01,  2.80667156e-01,\n",
       "          3.15714091e-01, -3.22796285e-01,  3.31817240e-01,\n",
       "         -2.61430234e-01, -3.38559896e-01,  4.84451056e-02,\n",
       "          3.09827238e-01, -2.43591338e-01,  5.80322444e-02,\n",
       "          3.00757378e-01,  3.14677805e-01, -1.52248830e-01,\n",
       "          2.58909762e-02,  1.87001795e-01, -2.73992449e-01,\n",
       "          2.50018626e-01, -1.99496210e-01],\n",
       "        [-2.03962088e-01, -1.81204647e-01, -3.51173759e-01,\n",
       "          3.11553627e-01,  8.05275440e-02, -3.35855663e-01,\n",
       "         -1.99391082e-01, -4.33665514e-03, -3.81485522e-02,\n",
       "          1.22413665e-01,  7.66209364e-02,  1.84675753e-02,\n",
       "         -2.02138305e-01, -3.31827611e-01,  1.85399622e-01,\n",
       "         -1.97432518e-01, -3.79502773e-04, -1.54954657e-01,\n",
       "          2.60405213e-01,  2.65972346e-01, -2.63292015e-01,\n",
       "         -1.71641260e-01,  2.61573285e-01,  2.95646042e-01,\n",
       "          1.83778137e-01, -1.29822493e-01, -5.66263199e-02,\n",
       "         -2.34320968e-01, -1.55719221e-02,  1.09863937e-01,\n",
       "         -2.94811904e-01,  2.85312086e-01],\n",
       "        [ 3.40558179e-02,  2.00829357e-01, -1.84473634e-01,\n",
       "         -1.61130607e-01, -2.96189755e-01, -3.08353633e-01,\n",
       "          4.99706358e-01, -8.75830650e-02,  1.45308495e-01,\n",
       "         -1.27939895e-01, -1.16586521e-01, -6.67832643e-02,\n",
       "         -9.35191661e-03,  1.38727516e-01, -2.79182512e-02,\n",
       "          1.08040623e-01, -3.19332629e-01, -2.35034168e-01,\n",
       "         -1.59490958e-01,  2.00818151e-01,  1.54993847e-01,\n",
       "          3.07315499e-01, -2.67311912e-02,  1.40528083e-01,\n",
       "          1.48269683e-01,  1.66550130e-02, -1.50331616e-01,\n",
       "          2.24731877e-01,  3.22734565e-01,  5.01211703e-01,\n",
       "          1.51534498e-01, -2.66265243e-01],\n",
       "        [-2.61035860e-01,  5.92852496e-02, -1.82977512e-01,\n",
       "         -3.15789402e-01, -2.16734439e-01,  1.56153992e-01,\n",
       "         -4.47241247e-01, -9.46614593e-02, -2.75671154e-01,\n",
       "          3.81401867e-01, -1.61734223e-02,  3.19232941e-01,\n",
       "          3.64412516e-01, -3.99507165e-01,  4.69988108e-01,\n",
       "          3.81897479e-01,  2.75331736e-01,  2.50765413e-01,\n",
       "          4.12972808e-01, -3.26212347e-01, -9.84627306e-02,\n",
       "         -1.96533456e-01,  1.73460275e-01,  3.70250344e-01,\n",
       "          2.50529200e-01, -2.49661446e-01,  5.05448937e-01,\n",
       "         -3.25997680e-01,  3.62609141e-02, -3.48004669e-01,\n",
       "          3.52721252e-02,  2.42037579e-01],\n",
       "        [ 1.03432819e-01, -7.55682215e-02,  3.04818243e-01,\n",
       "         -1.56890720e-01, -2.67094672e-01, -9.46714655e-02,\n",
       "         -1.15746997e-01, -1.66773215e-01, -1.71670690e-01,\n",
       "          2.10990489e-01, -2.15916365e-01, -6.88200863e-03,\n",
       "          4.99432504e-01,  9.19620395e-02,  1.55572221e-01,\n",
       "          5.11876822e-01,  1.81243703e-01,  8.10950994e-02,\n",
       "          4.88885432e-01, -3.86910409e-01, -3.88255537e-01,\n",
       "          1.87576085e-01,  3.62675488e-01,  4.50784862e-01,\n",
       "         -1.50363460e-01, -1.13338143e-01,  4.33652371e-01,\n",
       "         -2.50060737e-01,  1.74446125e-02, -7.35249668e-02,\n",
       "          2.55989909e-01, -2.54236795e-02],\n",
       "        [-1.50675505e-01,  3.89442816e-02, -2.57546902e-01,\n",
       "          2.54809648e-01, -3.44386280e-01, -1.34334445e-01,\n",
       "         -4.75644022e-01, -1.25205770e-01,  2.97216684e-01,\n",
       "          3.15137058e-01, -1.48100987e-01,  2.66791910e-01,\n",
       "          4.70034182e-01, -3.69018704e-01,  4.68632996e-01,\n",
       "          5.13701048e-03,  2.15475321e-01,  4.28154767e-02,\n",
       "          3.44114900e-01,  1.46267340e-01, -4.79375869e-01,\n",
       "         -2.34729499e-01,  2.89932609e-01,  2.16393508e-02,\n",
       "         -2.78067797e-01, -3.53332907e-01,  4.51645821e-01,\n",
       "         -1.12996109e-01, -2.34040663e-01, -3.90282422e-01,\n",
       "          1.52269050e-01,  6.38236254e-02],\n",
       "        [ 3.32968086e-01,  2.60009378e-01, -1.37029603e-01,\n",
       "         -3.95084620e-02, -2.65239209e-01, -2.90879160e-01,\n",
       "          2.43936509e-01,  9.40019786e-02,  2.38929480e-01,\n",
       "          2.57847995e-01, -8.18407536e-02, -2.53727823e-01,\n",
       "         -1.66780978e-01, -1.52141854e-01,  1.03951991e-01,\n",
       "          3.49357575e-01, -2.93680131e-02,  3.25741500e-01,\n",
       "         -2.48251349e-01, -1.27294272e-01, -2.71995366e-01,\n",
       "         -2.07438096e-01,  1.20138735e-01,  2.47224480e-01,\n",
       "         -3.27787161e-01, -3.51192236e-01,  2.58065850e-01,\n",
       "         -1.90318480e-01,  6.09747767e-02,  1.89563900e-01,\n",
       "          1.47824734e-01, -2.52079695e-01],\n",
       "        [-2.21325904e-01, -3.45935673e-01,  1.40760958e-01,\n",
       "         -3.60043645e-02, -1.84000745e-01,  1.73058480e-01,\n",
       "          2.56765097e-01, -1.51675373e-01,  2.47056395e-01,\n",
       "         -7.90246725e-02, -5.90401590e-02,  5.95346093e-02,\n",
       "         -2.60122329e-01,  1.61964685e-01, -1.75707430e-01,\n",
       "          2.42958218e-01, -3.48918080e-01,  2.29242533e-01,\n",
       "         -5.79752624e-02, -8.95841420e-02,  2.36217648e-01,\n",
       "          1.98619276e-01, -1.22199133e-01,  1.41122043e-02,\n",
       "         -7.65088499e-02,  2.78458148e-01, -1.55681431e-01,\n",
       "         -7.03443587e-02,  2.60790378e-01, -2.31389314e-01,\n",
       "          1.49303526e-01,  1.70845479e-01],\n",
       "        [ 1.34688705e-01, -2.39766598e-01,  2.47611612e-01,\n",
       "         -2.29047552e-01,  8.55082870e-02, -3.61203402e-01,\n",
       "          2.53645688e-01,  2.00463086e-02, -3.46615255e-01,\n",
       "          8.91896039e-02,  3.12580258e-01,  2.30379477e-01,\n",
       "         -9.95971635e-02,  4.44658607e-01,  2.87218153e-01,\n",
       "          3.84507403e-02,  2.12230444e-01, -2.05169499e-01,\n",
       "         -6.96214959e-02,  3.64891618e-01,  2.68419653e-01,\n",
       "         -2.80974925e-01, -1.06770536e-02,  1.19543418e-01,\n",
       "         -2.72556931e-01,  1.68407798e-01,  2.89530214e-02,\n",
       "          1.67001933e-01, -3.23560119e-01,  3.12999308e-01,\n",
       "         -6.48137331e-02, -1.92109630e-01],\n",
       "        [ 7.73049891e-02, -3.95935178e-02,  3.21562439e-01,\n",
       "         -2.51817554e-01,  1.60738379e-01, -2.03820467e-01,\n",
       "         -1.10067755e-01,  1.21575624e-01, -7.02678859e-02,\n",
       "          1.56212837e-01, -1.05944365e-01, -2.72031099e-01,\n",
       "          1.52214259e-01,  3.03360969e-01,  2.35850245e-01,\n",
       "          1.26933992e-01,  1.43083394e-01,  2.97610760e-02,\n",
       "         -5.00837862e-02, -5.60890138e-02, -1.47496939e-01,\n",
       "          8.17587376e-02,  4.18898463e-02, -2.73044109e-02,\n",
       "          2.22293437e-02, -9.50219929e-02,  2.86885351e-01,\n",
       "          2.08853811e-01,  1.69564098e-01,  3.12609464e-01,\n",
       "         -1.30982548e-01,  1.78020597e-02],\n",
       "        [-3.86613682e-02, -9.84591916e-02, -2.83738494e-01,\n",
       "         -3.61169875e-02,  2.55609751e-02,  1.62237525e-01,\n",
       "          5.89484908e-02,  6.08126260e-02, -2.24623144e-01,\n",
       "         -1.62488017e-02, -3.29204798e-01, -3.68345320e-01,\n",
       "          3.13891232e-01,  2.90277362e-01,  1.22137871e-02,\n",
       "         -9.22744535e-03,  1.60345927e-01, -2.07788259e-01,\n",
       "          1.64280325e-01,  1.62998766e-01,  2.45422512e-01,\n",
       "         -2.21079528e-01, -1.12189345e-01,  3.11173975e-01,\n",
       "         -9.08143371e-02,  4.99201156e-02, -5.67203276e-02,\n",
       "         -3.23686823e-02,  2.09024265e-01,  3.12753648e-01,\n",
       "          3.63022208e-01,  3.10061097e-01]], dtype=float32),\n",
       " array([ 0.10530999,  0.20528339,  0.        ,  0.        ,  0.        ,\n",
       "         0.03489245,  0.14929786, -0.02466585,  0.        , -0.02633423,\n",
       "         0.        ,  0.01137495, -0.07760069,  0.20454307, -0.08899345,\n",
       "        -0.0591318 , -0.05929025,  0.        , -0.07481299,  0.16519223,\n",
       "         0.12170657, -0.00051714, -0.04355908, -0.11786869, -0.00051711,\n",
       "         0.11549646, -0.03587538, -0.05606153, -0.01067629,  0.16878325,\n",
       "        -0.08816282,  0.00051702], dtype=float32),\n",
       " array([[ 0.07212228, -0.4730727 ],\n",
       "        [ 0.37819532, -0.3339208 ],\n",
       "        [-0.10227674, -0.06270367],\n",
       "        [ 0.21152171, -0.22132657],\n",
       "        [-0.14159232,  0.22852388],\n",
       "        [ 0.23348331,  0.13871631],\n",
       "        [ 0.63650054, -0.6799937 ],\n",
       "        [-0.32684508,  0.3875719 ],\n",
       "        [-0.28261092,  0.00767034],\n",
       "        [-0.15417747,  0.391397  ],\n",
       "        [ 0.07696936, -0.3923757 ],\n",
       "        [-0.2961531 , -0.22753344],\n",
       "        [-0.5414451 ,  0.1355381 ],\n",
       "        [ 0.03622418, -0.65245765],\n",
       "        [-0.42933497,  0.5575031 ],\n",
       "        [-0.307456  ,  0.0484895 ],\n",
       "        [-0.5513501 ,  0.05805184],\n",
       "        [-0.40744847,  0.2163122 ],\n",
       "        [-0.53583115, -0.05617232],\n",
       "        [ 0.578718  , -0.48889342],\n",
       "        [ 0.51938003, -0.67182165],\n",
       "        [-0.09450189,  0.39648286],\n",
       "        [-0.52328354, -0.01372153],\n",
       "        [-0.12966068,  0.23228417],\n",
       "        [-0.11606473,  0.22182232],\n",
       "        [ 0.05348082, -0.21924928],\n",
       "        [ 0.17885575,  0.6218571 ],\n",
       "        [-0.3324287 , -0.27128416],\n",
       "        [ 0.26004818,  0.3849524 ],\n",
       "        [ 0.51727057, -0.42365265],\n",
       "        [-0.56382453,  0.45944154],\n",
       "        [ 0.12995726, -0.0492641 ]], dtype=float32),\n",
       " array([ 0.10209313, -0.10209312], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Adam at 0x2276d5ba4e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"keras_version\": \"2.2.2\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Save as Json\n",
    "\n",
    "# Only saves the architecture #\n",
    "\n",
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "model_architecture = model_from_json(json_string)\n",
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving model weights only#\n",
    "\n",
    "model.save_weights(\"medical_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(16, input_shape = (1,), activation='relu'), #number of neurons in layer, only this layer needs input shape (1D)\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dense(2, activation = 'softmax') #output layer, 2 nodes for 2 classes (young/old)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"medical_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
